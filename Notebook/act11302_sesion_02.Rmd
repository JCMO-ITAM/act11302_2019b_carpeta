---
title: "Sesion 02 - Aprendizaje Estadistico"
author:
-  Juan Carlos Martínez-Ovando
date: "Otoño 2019"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: yes
    self_contained: yes
    theme: cerulean # cosmo
    highlight: textmate
fig_align: "center"
fig_width: 18

header-includes:
    - \usepackage[most]{tcolorbox}
    - \definecolor{light-yellow}{rgb}{1, 0.95, 0.7}
    - \newtcolorbox{myquote}{colback=light-yellow,grow to right by=-10mm,grow to left by=-10mm, boxrule=0pt,boxsep=0pt,breakable}
    - \newcommand{\todo}[1]{\begin{myquote} \textbf{TODO:} \emph{#1} \end{myquote}}

---

\newcommand{\WiD}{\operatorname{\text{Wi}}}
\newcommand{\WeD}{\operatorname{\text{We}}}
\newcommand{\WeNormD}{\operatorname{\text{We-N}}}
\newcommand{\ExpD}{\operatorname{\text{Exp}}}
\newcommand{\GeoD}{\operatorname{\text{Geo}}}
\newcommand{\StD}{\operatorname{\text{St}}}
\newcommand{\NormD}{\operatorname{\text{N}}}
\newcommand{\GaD}{\operatorname{\text{Ga}}}
\newcommand{\BeD}{\operatorname{\text{Be}}}
\newcommand{\UniD}{\operatorname{\text{U}}}
\newcommand{\DirD}{\operatorname{\text{Dir}}}
\newcommand{\IG}{\operatorname{\text{InG}}}
\newcommand{\IncGa}{\operatorname{\text{IGa}}}
\newcommand{\IGa}{\operatorname{\text{InGa}}}
\newcommand{\PoD}{\operatorname{\text{Po}}}
\newcommand{\BS}{\operatorname{\text{BS}}}
\newcommand{\DP}{\operatorname{\text{DP}}}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\Borel}{\operatorname{\mathscr{B}}}
\newcommand{\Filtration}{\operatorname{\mathscr{F}}}
\newcommand{\Expec}{\operatorname{\field{E}}}



---

# Objetivo {.tabset .tabset-fade .tabset-pills}

* En esta sesion revisaremos algunas ideas generales de los procedimientos estadisticos *inferencial* y *predictivo* basados en el **paradigma frecuentista** y el **paradigma bayesiano**.

---

# Aprendizaje Estadístico {.tabset .tabset-fade .tabset-pills}

## Modelos de Probabilidad

Recordemos, de la sesion anterior, que $X$ es una variable aleatoria con
$$
X \sim F_X(x|\theta),
$$
donde 

* $F_X(\cdot)$ es una *funcion de distribuciones de probabilidad* dentro de la **clase de distribuciones** $$\mathcal{F}=\{F_X(x|\theta):\theta\in\Theta\}$$

* $\theta$ es un parametro (indice de modelos especificos) dentro del **espacio parametral** $\Theta$

* la variable aleatoria $X$ toma valores en el **soporte** $\mathcal{X}$.

### Comentarios


* Cada modelo especifico en $\mathcal{F}$ (a.k.a. $F_X(x|\theta)$ con un valor de $\theta$ especifico) sirve para *cuantificar nuestra incertidumbre* respecto a la realizacion de la variable $X$.

* Nuestra *incertidumbre acerca de la realizacion de* $X$ se le conoce como **INCERTIDUMBRE ALEATORIA**.

* Nuestra *incertidumbre acerca del modelo especifico (valor especifico de $\theta$ en $\mathcal{F}$)* se le conoce como **INCERTIDUMBRE EPISTEMICA**.


El **aprendizaje estadistico** nos permite controlar/mitigar el efecto de la *incertiumbre epistemica* para dar una *mejor lectura* de la *incertidumbre aleatoria*.

## Datos {.tabset .tabset-fade .tabset-pills}

> El aprendizaje estadistico toma lugar combinando el **grado de compatibilidad** entre los modelos dentro de una clase y un conjunto de informacion relevante. 

La informacion relevante es de la siguiente naturaleza:

1. Informacion cuantitativa (**datos/observaciones**) del fenomeno

2. Informacion cualitativa (**suplementaria/teorica/contextual**) del fenomeno.

Los procedimientos de aprendizaje estadistico estan disenados para extrear/consolidar de la mejor manera posible ambas fuentes de informacion. 

> La metrica para medir el grado de compatibilidad entre el modelo expecifico y la informacion cuantitativa disponible se obtiene a traves de la **FUNCION DE VEROSIMILITUD**.

## Verosimilitud {.tabset .tabset-fade .tabset-pills}

Consideremos un conjunto de informacion cuantitativa/datos, dados por 
$$\{x_1,x_2,\ldots,x_n\}$$.

> Los datos no necesariamente corresponden a realizaciones de variables aleatorias, son simplemente informacion.

Vinculamos un modelo de probabilidad $$X\sim F_X{x|\theta}$$ con esta informacion cuantitativa **suponiendo/imponiendo** 
$$X_1=x_1,\ldots,X_n=x_n.$$
De esta forma, la funcion de verosimilitud de define como la probabilidad conjunta de $(x_1,\ldots,x_n)$, i.e.
$$
lik(\theta;x_1,\ldots,x_n)=\Pr(X_1=x_1,\ldots,X_n=x_n|\theta)=
\begin{cases}
f_{X_1,\ldots,X_n}(x_1,\ldots,x_n|\theta), & \text{caso absolutamente continuo} \\
p_{X_1,\ldots,X_n}(x_1,\ldots,x_n|\theta), & \text{caso discreto}
\end{cases}
$$
donde

* $f_{X_1,\ldots,X_n}(x_1,\ldots,x_n|\theta)$ es la funcion de densidad

* $p_{X_1,\ldots,X_n}(x_1,\ldots,x_n|\theta)$ es la funcion de masa de probabilidades,

ambas evaluadas en los datos $(x_1,\ldots,x_n)$.

> Valores grandes de $lik(\theta;x_1,\ldots,x_n)$ para un valor especifico de $\theta$ representa alta compatibilidad del modelo especifico $F_X(\cdot|\theta)$ con los datos.

El computo de $lik(\theta;x_1,\ldots,x_n)$ requiere de ciertas simplificaciones **atribuibles al modelo y no a los datos**. Tales simplificaciones hacen referencia a la forma en como **creemos** que los datos, $(x_1,\ldots,x_n)$, se relacionan entre si a traves del modelo de probabilidad $F_X(\cdot|\theta)$.

## Dependencia estocastica {.tabset .tabset-fade .tabset-pills}

Las estructuras de dependencia estocastica alusen a la nocion de simetria en los datos a traves de $F_X(\cdot|\theta)$. En el curso trabajaremos con dos estructuras, particularmente, de cuatro que prevalecen en la modelacion actual:

1. Independencia estocastica bajo homogeneidad (caso *iid*)

2. Intercambiabilidad

3. Estacionariedad

4. Homogeneidad espacial.

De estos, solo (1) y (2) seran revisados en esta sesion.

### Independencia estocastica bajo homogeneidad

En este supuesto dos condiciones prevalecen:

a. A traves del modelo $F_X(\cdot|\theta)$ las variables aleatorias $X_1,\ldots,X_n$ son mutueamente independientes, y

b. Cada variable $X_j$ es homogenea a las demas, i.e. el modelo marginal para cada variable aleatoria es el mismo, $X_j\sim F_X(\cdot|\theta)$.

Bajo estas consideraciones, es posible obtener la simplificacion

$$
lik(\theta;x_1,\ldots,x_n) = \prod_{i=1}^{n} p_X(x_i;\theta),
$$
para el caso discreto. La expresion es analoga para el caso absolutamente continuo.

### Intercambialidad

El supuesto de intercambiabilidad es tambien de simetria, bajo el cual:

a. Cada variable aleatoria $X_j$ tiene asociado el mismo modelo marginal, i.e. $X_j\sim F_X(\cdot|\theta)$

b. El modelo de probabilidad conjunto es invariante ante permutaciones, i.e. 
$$
\Pr(X_1=x_1,\ldots,X_n=x_n) =
\Pr(X_{\sigma(1)}=x_1,\ldots,X_{\sigma(n)}=x_n),
$$
donde $\{\sigma(1),\ldots,\sigma(n)\}$ denota cualquier permutacion de los indices $\{1,\ldots,n\}$.

> Noten que en la definicion de arriba no he hecho mencion de $\theta$. Por que?

Bajo (a) y (b) arriba obtenemos que **condicional en $\theta$** las variables aleatorias $X_1,\ldots,X_n$ son independientes, por lo que la verosimilitud adopta la simplificacion

$$
lik(\theta|x_1,\ldots,x_n) = \prod_{i=1}^{n} p_X(x_i|\theta),
$$
para el caso discreto. La expresion es analoga al caso absolutamente continuo.

### Comentarios

* Los supuestos *iid* y de *intercambialidad* hacen referencia a la nocion de simetria ante permutaciones, i.e. el modelo de probabildad no presta atencion al orden en el que los datos se manifiesten/recolecten.

* Ambos supuestos parecen ser redundantes, pero no es asi. El supuesto de intercambiabilidad implica que la correlacion entre cualquier pareja $(X_i,X_j)$, con $i\neq j$, es mayor a cero.

> El ultimo punto es de suma relevancia en el calculo del riesgo agregado.

Veamos un ejemplo con el modelo Bernoulli (el mas sencillo de este curso).

---

# Modelo Bernoulli  {.tabset .tabset-fade .tabset-pills}

Este es el modelo base para la modelacion de riesgos. 

Suponemos que $X$ denota la realizacion de dos poribles resultados,
$$
X = 
\begin{cases}
0, & \text{ no ocurre un siniestro}\\
1, & \text{ ocurre un siniestro}.
\end{cases}
$$
El soporte de esta variable aleatoria es 
$$
\mathcal{X}=\{0,1\}.
$$

El modelo de probabilidad para esta $X$ es el Bernoulli, con
\begin{eqnarray}
\Pr(X=0|\theta) & = & \theta, \\
\Pr(X=1|\theta) & = & 1-\theta.
\end{eqnarray}

Por ser una medida de probabilidad, el espacio parametral es
$$
\Theta=(0,1).
$$

Este modelo lo podemos reexpresar como
$$
\Pr(X=x|\theta) = \theta \delta_{\{0\}}(x) + (1-\theta)\delta_{\{1\}}(x),
$$
para $x\in \mathcal{X}$.

> La funcion $\delta_{\{0\}}(x)$ se conoce como la funcion **delta de Dirac**, que es una medida de probabilidad degenerada en el atomo $\{0\}$ en este caso.

## Datos

Consideremos el siguiente conjunto de 100 datos:
```{R}
shotData<- c(1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,
             1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,
             0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
             1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0)

table(shotData)
```

```{r include=FALSE}
perm_init = function(n) {
  result = list(data = c(1:n), n = n)
  return(result)
}

perm_rnd = function(n) {
  result = perm_init(n)
  result$data = sample(1:n)
  return(result)
}
```

La idea de la simetria estocastica hace referencia a que el modelo y el procedo de aprendizaje seran invariantes antes permutaciones del orden de los datos, i.e.
```{r}
plot(shotData,xlab="Num. Poliza",ylab="Siniestro")

plot(shotData[perm_rnd(100)[[1]]],xlab="Indice permutado",ylab="Diagnostico")
```

## Verosimilitud


La funcion de verosimilitud, en este caso, se calcula como
\begin{eqnarray}
lik(\theta|\text{datos}) 
& = &
  \prod_{i=1}^{n} \Pr(X=x_i|\theta) \\
& = & 
  \prod_{i=1}^{n} \left(\theta \delta_{\{0\}}(x_i) + (1-\theta)\delta_{\{1\}}(x_i)\right) \\
& = & 
  \prod_{\{i:x_i=0\}} \theta \delta_{\{0\}}(x_i) \prod_{\{i:x_i=1\}} (1-\theta)\delta_{\{1\}}(x_i) \\
& = & 
   \theta^{\#\{i:x_i=0\}} \times (1-\theta)^{\#\{i:x_i=1\}}.
\end{eqnarray}

> Noten que la expresion anterior es analoga tanto para el **supuesto** *iid* como el de *intercambiabilidad*.


```{r}
x <- seq(.001, .999, .001)
y2 <- dbeta(x, 1 + 42, 1 + 58)

plot(x, y2, xlim=c(0,1), ylim=c(0, 1.25 * max(y2,1.6)), type = "l", 
     ylab= "Verosimilitud", lty = 3,
     xlab= "P(X=0|theta)", las=1, lwd=2,
     cex.lab=1.5, cex.main=1.5, col = "darkorange", axes=FALSE)
axis(1, at = seq(0,1,.2))
axis(2, las=1)
```

## Aprendizaje frecuentista

El aprendizaje estadistico frecuentista solo toma enconsideracion la *informacion cuantitativa de los datos*.

El paradigma, *grosso modo*, dicta que el mejor modelo expecifico es el que es **mas compatible con los datos**, i.e. el modelo 
$$
F_X(\cdot|\hat{\theta}),
$$
tal que
$$
\hat{\theta}=\arg\max_{\theta\in\Theta} lik(\theta|\text{datos}).
$$
En este caso, 
$$
\hat{\theta} = 42/100.
$$

Asi, el modelo especifico es:

```{r}
shotDatab <- table(shotData)/100
shotDatab
plot(shotDatab, ylab='P(X=x|theta)', xlab='x')
```

> Noten que bajo la verosimilitud, *estadisticamente*, los valores de $\theta=0.45$ y $\theta=0.39$ (como otros) son extadisticamente equivalentes.

## Aprendizaje bayesiano

El aprendizaje bayesiano consiste en combinar dos fuentes de informacion:

1. Cuantitativa

2. Cualitativa

> La informacion cualitativa se calcula con base en una **medida de probabilidad para $\theta$** con soporte en $\Theta$.

Esa medida de probabilidad se conoce como **prior** o **distribucion inicial**, y se denota por
$$
\pi(\theta).
$$
En este modelo particular Bernooulli, una $\pi(\theta)$ conveniente es la que sea *semejante funcionalmente a la verosimilitud*,
$$
lik(\theta|\text{datos}) = \theta^{\#\{i:x_i=0\}} \times (1-\theta)^{\#\{i:x_i=1\}}.
$$

En este caso, la opcion correspondientes seria la medida de probabilidad beta, con funcion de densidad
\begin{eqnarray}
\pi(\theta|a,b)
 & = & \frac{\Gamma(a,b)}{\Gamma(a)\Gamma(b)} \theta^{a-1}(1-\theta)^{b-1}\mathbb{I}_{(0,1)}(\theta)\\
 & \propto & \theta^{a-1} \times (1-\theta)^{b-1},
\end{eqnarray}
para $\theta \in \Theta=(0,1)$, con $a,b > 0$.

> Los valores de $a$ y $b$ se conocen como **hiperparametros** y cuantifican la **informacion cualitativa acerca del modelo especifico**.

> El procedimiento para *traducir* la **informacion cualitativa** en una **prior** se conoce como **LICITACION DE DISTRIBUCIONES** (que exploraremos a lo largo del curso).

> La informacion cualitativa es de particular importancia cuando la informacion cuantitativa es limitada. esto es relevante en varios contextos de riesgos que exploraremos en el curso.

El **aprendizaje bayesiano** toma lugar combinando la *verosimilitud* con la *prior* empleando el **Teorema de Bayes**, i.e.
\begin{eqnarray}
\pi(\theta|\text{datos})
 & = & \frac{p(\text{datos}|\theta)\pi(\theta)}{p(\text{datos})} \\
 & \propto & p(\text{datos}|\theta)\pi(\theta) \\
 & \propto & lik(\theta;\text{datos})\pi(\theta) \\
 & \propto & p(\text{datos}|\theta)\pi(\theta) \\
 & = & \theta^{\#\{i:x_i=0\}} \times (1-\theta)^{\#\{i:x_i=1\}} \theta^{a-1} \times (1-\theta)^{b-1} \\
 & = & \theta^{\#\{i:x_i=0\}+a-1} \times (1-\theta)^{\#\{i:x_i=1\}+b-1}. 
\end{eqnarray}

Esta ultima expresion corresponde al *kernel* de la distribucion beta con parametros
$$
\#\{i:x_i=0\}+a \\
\text{ y } \\
\#\{i:x_i=1\}+b.
$$

> Asi como $\pi(\theta)$ se refiere a la **prior**, la nueva medida de probabilidad $\pi(\theta|\text{datos})$ se refiere a la **porterior**.


```{r include=FALSE}
plot.beta <- function(PS = 1, PF = 1, k = 0, n = 0, null = NULL, CI = NULL, ymax = "auto", main = NULL) {
        
        x = seq(.001, .999, .001)
        y1 = dbeta(x, PS, PF)
        y3 = dbeta(x, PS + k, PF + n - k)
        y2 = dbeta(x, 1 + k, 1 + n - k)
        
        if(is.numeric(ymax) == T){
                y.max = ymax
        }        
        else(
                y.max = 1.25 * max(y1,y2,y3,1.6)
        )
        
        if(is.character(main) == T){
                Title = main
        }
        else(
                Title = "Prior-to-Posterior"
        )
        
        
        plot(x, y1, xlim=c(0,1), ylim=c(0, y.max), type = "l", ylab= "Densidad", lty = 2,
             xlab= "P(X=x|theta)", las=1, main= Title,lwd=3,
             cex.lab=1.5, cex.main=1.5, col = "skyblue", axes=FALSE)
        
        axis(1, at = seq(0,1,.2))
        axis(2, las=1)
        
        
        
        if(n != 0){
                lines(x, y2, type = "l", col = "darkorange", lwd = 2, lty = 3)
                lines(x, y3, type = "l", col = "darkorchid1", lwd = 5)
                legend("topleft", c("Prior", "Posterior", "Likelihood"), col = c("skyblue", "darkorchid1", "darkorange"), 
                       lty = c(2,1,3), lwd = c(3,5,2), bty = "n", y.intersp = .55, x.intersp = .1, seg.len=.7)
                
                ## adds null points on prior and posterior curve if null is specified and there is new data
                if(is.numeric(null) == T){
                        ## Adds points on the distributions at the null value if there is one and if there is new data
                        points(null, dbeta(null, PS, PF), pch = 21, bg = "blue", cex = 1.5)
                        points(null, dbeta(null, PS + k, PF + n - k), pch = 21, bg = "darkorchid", cex = 1.5)
                        abline(v=null, lty = 5, lwd = 1, col = "grey73")
                        ##lines(c(null,null),c(0,1.11*max(y1,y3,1.6))) other option for null line
                }
        }
        
        ##Specified CI% but no null? Calc and report only CI
        if(is.numeric(CI) == T && is.numeric(null) == F){
                CI.low <- qbeta((1-CI)/2, PS + k, PF + n - k)
                CI.high <- qbeta(1-(1-CI)/2, PS + k, PF + n - k)
                
                SEQlow<-seq(0, CI.low, .001)
                SEQhigh <- seq(CI.high, 1, .001)
                ##Adds shaded area for x% Posterior CIs
                cord.x <- c(0, SEQlow, CI.low) ##set up for shading
                cord.y <- c(0,dbeta(SEQlow,PS + k, PF + n - k),0) ##set up for shading
                polygon(cord.x,cord.y,col='orchid', lty= 3) ##shade left tail
                cord.xx <- c(CI.high, SEQhigh,1) 
                cord.yy <- c(0,dbeta(SEQhigh,PS + k, PF + n - k), 0)
                polygon(cord.xx,cord.yy,col='orchid', lty=3) ##shade right tail
                
                return( list( "Posterior CI lower" = round(CI.low,3), "Posterior CI upper" = round(CI.high,3)))
        }
        
        ##Specified null but not CI%? Calculate and report BF only 
        if(is.numeric(null) == T && is.numeric(CI) == F){
                null.H0 <- dbeta(null, PS, PF)
                null.H1 <- dbeta(null, PS + k, PF + n - k)
                CI.low <- qbeta((1-CI)/2, PS + k, PF + n - k)
                CI.high <- qbeta(1-(1-CI)/2, PS + k, PF + n - k)
                return( list("BF01 (in favor of H0)" = round(null.H1/null.H0,3), "BF10 (in favor of H1)" = round(null.H0/null.H1,3)
                ))
        }
        
        ##Specified both null and CI%? Calculate and report both
        if(is.numeric(null) == T && is.numeric(CI) == T){
                null.H0 <- dbeta(null, PS, PF)
                null.H1 <- dbeta(null, PS + k, PF + n - k)
                CI.low <- qbeta((1-CI)/2, PS + k, PF + n - k)
                CI.high <- qbeta(1-(1-CI)/2, PS + k, PF + n - k)
                
                SEQlow<-seq(0, CI.low, .001)
                SEQhigh <- seq(CI.high, 1, .001)
                ##Adds shaded area for x% Posterior CIs
                cord.x <- c(0, SEQlow, CI.low) ##set up for shading
                cord.y <- c(0,dbeta(SEQlow,PS + k, PF + n - k),0) ##set up for shading
                polygon(cord.x,cord.y,col='orchid', lty= 3) ##shade left tail
                cord.xx <- c(CI.high, SEQhigh,1) 
                cord.yy <- c(0,dbeta(SEQhigh,PS + k, PF + n - k), 0)
                polygon(cord.xx,cord.yy,col='orchid', lty=3) ##shade right tail
                
                return( list("BF01 (in favor of H0)" = round(null.H1/null.H0,3), "BF10 (in favor of H1)" = round(null.H0/null.H1,3),
                             "Posterior CI lower" = round(CI.low,3), "Posterior CI upper" = round(CI.high,3)))
        }
        
}
```

### Priors

```{r}
plot.beta(1,1,ymax=3.2,main="Prior uniforme, Beta(1,1)")
plot.beta(.5,.5,ymax=3.2,main="Jeffreys's Prior, Beta(1/2,1/2)")
plot.beta(4,9,ymax=3.2,main="Prior informativa, Beta(4,9)")

```

### Posteriores

#### Caso 1

Cuando consideramos solo 38 datos de los cuales $13$ son no siniestro, tenemos lo siguiente:

```{r}
plot.beta(1,1,13,25,main="Beta(1,1) -> Beta(14,13)",ymax=10)
plot.beta(.5,.5,13,25,main="Beta(1/2,1/2) -> Beta(13.5,12.5)",ymax=10)
plot.beta(4,9,13,25,main="Beta(4,9) -> Beta(17,21)",ymax=10)
```

#### Caso 2

Cuando agregamos 37 datos de los cuales $12$ son no siniestro, tenemos lo siguiente:

```{r}
plot.beta(14,13,12,25,ymax=10,main="Beta(14,13) -> Beta(26,26)")
plot.beta(13.5,12.5,12,25,ymax=10,main="Beta(13.5,12.5) -> Beta(25.5,25.5)")
plot.beta(17,21,12,25,ymax=10,main="Beta(17,21) -> Beta(29,34)")
```

#### Caso 3

Cuando agregamos 39 datos mas de los cuales $14$ son no siniestro, tenemos lo siguiente:

```{r}
plot.beta(26,26,14,25,ymax=10,main="Beta(26,26) -> Beta(40,37)")
plot.beta(25.5,25.5,14,25,ymax=10,main="Beta(25.5,25.5) -> Beta(39.5,36.5)")
plot.beta(29,34,14,25,ymax=10,main="Beta(29,34) -> Beta(43,45)")
```

#### Caso 4

Cuando agregamos 44 datos mas  de los cuales $19$ son no siniestro, tenemos lo siguiente:

```{r}
plot.beta(40,37,19,25,ymax=10,main="Beta(40,37) -> Beta(59,43)")
plot.beta(39.5,36.5,19,25,ymax=10,main="Beta(39.5,36.5) -> Beta(58.5,42.5)")
plot.beta(43,45,19,25,ymax=10,main="Beta(43,45) -> Beta(62,51)")
```

#### Caso agregado

Cuando consideramos la agregacion de todos los datos disponibles, tenemos lo siguiente:

```{r}
plot.beta(1,1,58,100,ymax=10,main="Beta(1,1) -> Beta(59,43)")
plot.beta(.5,.5,58,100,ymax=10,main="Beta(1/2,1/2) -> Beta(58.5,42.5)")
plot.beta(4,9,58,100,ymax=10,main="Beta(4,9) -> Beta(62,51)")
```


# Predicción

Para efectos de nuestro curso, el proposito principal de un modelo es el predictivo, es decir, anticipar lo que pasara con una y varias polizas con base en la informacion de siniestralidad (y reclamos) de polizas pasadas semejantes.

## Enfoque frecuentista

Bajo el enfoque frecuentista, la prediccion de un valor futuro de $X$, $X^f$, se obtiene a trav\'es de la imputacion del EMV de $\theta$ en el modelo, i.e.
\begin{equation}
 X^f|x_1\ldots,x_n \sim f(x^f|\widehat{\theta}_n),
\end{equation}
donde $\widehat{\theta}_n=\widehat{\theta}_n(x_1\ldots,x_n)$.

> Esto porque la funcion de verosimilitud no permite incorporar el grado de diferenciacion entre diferentes modelos especificos en una escala comparable.

## Enfoque bayesiano

Bajo el enfoque bayesiano, la predicci\'on se obtiene usando argumentos probabilisticos, como
\begin{equation}
  p(x^f|x_1\ldots,x_n) = \int_{\Theta} f(x^f|\theta) \pi(\theta|x_1\ldots,x_n)\dd \theta,
\end{equation}
donde $\pi(\theta|x_1\ldots,x_n) \propto f(x_1\ldots,x_n|\theta)\pi(\theta)$ es la distribuci\'on de $\theta$ actualizada con la informaci\'on contenida en $x_1\ldots,x_n$.

> Esto porque la informacion cualitativa y cuantitativa consolidada en $\pi(\theta|\text{datos})$ resume toda la informacion en una medica de probabilidad comparable para todos los valores de $\theta$.


# Ejercicios

Consideremos el caso sencillo donde $X$ es discreta con $\mathcal{X}=\{0,1\}$.

1. Defina el modelo de probabilidad para $X$. 

2. Identifique el parametro del modelo.

3. Defina la verosimilitud para el par\'ametro basado en el supuesto de $independencia$ con base en tres datos $x_1=1$, $x_2=1$ y $x_3=1$.

4. Calcule la distribuci\'on predictiva para $X_4$.

5. Examine la forma gen\'erica de la funci\'on de verosimilitud para el par\'ametro del modelo.

6. Identifique la distribucion $\pi$ conjugada (semejante).

7. Calcule la distribuci\'on predictiva para $X_4$ usando los mismos datos empleados anteriormente, $x_1,x_2,x_3$.

Realicen todos los calculos en el ejercicio de manera analitica.